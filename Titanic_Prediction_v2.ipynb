{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Titanic_train.csv') # 891 rows x 12 columns\n",
    "test_df = pd.read_csv('Titanic_test.csv')   # 419 rows x 11 columns (doesn't include 'Survived' feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  SibSp  Parch  Miss  Mrs  Mr.  Master  Other  \\\n",
      "0            1         0       3      1      0     0    0    1       0      0   \n",
      "1            2         1       1      1      0     0    1    0       0      0   \n",
      "2            3         1       3      0      0     1    0    0       0      0   \n",
      "3            4         1       1      1      0     0    1    0       0      0   \n",
      "4            5         0       3      0      0     0    0    1       0      0   \n",
      "\n",
      "    ...    C  D  E  F  G  H  T  Z  Male  Female  \n",
      "0   ...    0  0  0  0  0  0  0  1     1       0  \n",
      "1   ...    1  0  0  0  0  0  0  0     0       1  \n",
      "2   ...    0  0  0  0  0  0  0  1     0       1  \n",
      "3   ...    1  0  0  0  0  0  0  0     0       1  \n",
      "4   ...    0  0  0  0  0  0  0  1     1       0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "   PassengerId  Pclass  SibSp  Parch  Miss  Mrs  Mr.  Master  Other  A  \\\n",
      "0          892       3      0      0     0    0    1       0      0  0   \n",
      "1          893       3      1      0     0    1    0       0      0  0   \n",
      "2          894       2      0      0     0    0    1       0      0  0   \n",
      "3          895       3      0      0     0    0    1       0      0  0   \n",
      "4          896       3      1      1     0    1    0       0      0  0   \n",
      "\n",
      "    ...    C  D  E  F  G  H  T  Z  Male  Female  \n",
      "0   ...    0  0  0  0  0  0  0  1     1       0  \n",
      "1   ...    0  0  0  0  0  0  0  1     0       1  \n",
      "2   ...    0  0  0  0  0  0  0  1     1       0  \n",
      "3   ...    0  0  0  0  0  0  0  1     1       0  \n",
      "4   ...    0  0  0  0  0  0  0  1     0       1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "def prep_data(df):\n",
    "    # drop the following features\n",
    "    #df = df.drop('PassengerId', axis=1)\n",
    "    #df = df.drop('Name', axis=1)            DELETE THIS WHEN DONE WITH NAME\n",
    "    df = df.drop('Ticket', axis=1)\n",
    "    df = df.drop('Embarked', axis=1)\n",
    "    df = df.drop('Fare', axis=1)\n",
    "    df = df.drop('Age', axis=1) # Lots of NaNs, create a 'Title' feature from the 'Name' feature instead.\n",
    "    \n",
    "    # Create Title feature from Name feature\n",
    "    df['Title'] = df['Name']\n",
    "    #df['Name'].str.contains('Miss') # boolean vector\n",
    "    for i in range(df['Name'].size):\n",
    "        if 'Miss' in df.iloc[i]['Name']:\n",
    "            df.set_value(i, 'Title', 'Miss')\n",
    "        elif 'Mrs' in df.iloc[i]['Name']:\n",
    "            df.set_value(i, 'Title', 'Mrs')\n",
    "        elif 'Mr.' in df.iloc[i]['Name']:\n",
    "            df.set_value(i, 'Title', 'Mr.')\n",
    "        elif 'Master' in df.iloc[i]['Name']:\n",
    "            df.set_value(i, 'Title', 'Master')\n",
    "        else:\n",
    "            df.set_value(i, 'Title', 'Other')\n",
    "            \n",
    "    df['Miss'] = pd.Series(df['Title'].values, index=df.index)\n",
    "    df['Miss'] = df['Miss'].map({'Miss':1, 'Mrs':0, 'Mr.':0, 'Master':0, 'Other':0})\n",
    "    df['Mrs'] = pd.Series(df['Title'].values, index=df.index)\n",
    "    df['Mrs'] = df['Mrs'].map({'Miss':0, 'Mrs':1, 'Mr.':0, 'Master':0, 'Other':0})\n",
    "    df['Mr.'] = pd.Series(df['Title'].values, index=df.index)\n",
    "    df['Mr.'] = df['Mr.'].map({'Miss':0, 'Mrs':0, 'Mr.':1, 'Master':0, 'Other':0})\n",
    "    df['Master'] = pd.Series(df['Title'].values, index=df.index)\n",
    "    df['Master'] = df['Master'].map({'Miss':0, 'Mrs':0, 'Mr.':0, 'Master':1, 'Other':0})\n",
    "    df['Other'] = pd.Series(df['Title'].values, index=df.index)\n",
    "    df['Other'] = df['Other'].map({'Miss':0, 'Mrs':0, 'Mr.':0, 'Master':0, 'Other':1})\n",
    "    \n",
    "    df = df.drop('Title', axis=1)\n",
    "    df = df.drop('Name', axis=1)\n",
    "    \n",
    "    \n",
    "    #print(df['Title'])\n",
    "   \n",
    "    # create the cabin-level feature to factors : A, B, C, D, E, F, G, T, and change NaN to Z\n",
    "    df['Cabin'] = df['Cabin'].fillna('Z')\n",
    "    df['Cabin'] = df['Cabin'].astype(str).str[0]\n",
    "    \n",
    "    # change the cabin-level factors to binary indicator variables\n",
    "    df['A'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['A'] = df['A'].map({'A':1, 'B':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'T':0, 'Z':0})\n",
    "    df['B'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['B'] = df['B'].map({'A':0, 'B':1, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'T':0, 'Z':0})\n",
    "    df['C'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['C'] = df['C'].map({'A':0, 'B':0, 'C':1, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'T':0, 'Z':0})\n",
    "    df['D'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['D'] = df['D'].map({'A':0, 'B':0, 'C':0, 'D':1, 'E':0, 'F':0, 'G':0, 'H':0, 'T':0, 'Z':0})\n",
    "    df['E'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['E'] = df['E'].map({'A':0, 'B':0, 'C':0, 'D':0, 'E':1, 'F':0, 'G':0, 'H':0, 'T':0, 'Z':0})\n",
    "    df['F'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['F'] = df['F'].map({'A':0, 'B':0, 'C':0, 'D':0, 'E':0, 'F':1, 'G':0, 'H':0, 'T':0, 'Z':0})\n",
    "    df['G'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['G'] = df['G'].map({'A':0, 'B':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':1, 'H':0, 'T':0, 'Z':0})\n",
    "    df['H'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['H'] = df['H'].map({'A':0, 'B':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':1, 'T':0, 'Z':0})\n",
    "    df['T'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['T'] = df['T'].map({'A':0, 'B':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'T':1, 'Z':0})\n",
    "    df['Z'] = pd.Series(df['Cabin'].values, index=df.index)\n",
    "    df['Z'] = df['Z'].map({'A':0, 'B':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'T':0, 'Z':1})\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    \n",
    "    # change 'Sex' feature to Male and Female binary indicator variables\n",
    "    df['Male'] = pd.Series(df['Sex'].values, index=df.index)\n",
    "    df['Male'] = df['Male'].map({'male': 1, 'female': 0})\n",
    "\n",
    "    df['Female'] = pd.Series(df['Sex'].values, index=df.index)\n",
    "    df['Female'] = df['Female'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    df = df.drop('Sex', axis=1)\n",
    "\n",
    "    # shuffle the rows        disabled this for now because you need the indices of test_df when submitting to Kaggle\n",
    "    #df = df.sample(frac=1)\n",
    "    \n",
    "    # normalize the inputs\n",
    "    #df = (df - df.mean(axis=0))/df.std(axis=0)  didn't work\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = prep_data(train_df)\n",
    "test_df = prep_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 891\n",
      "number of test examples = 418\n",
      "X_train shape: (21, 891)\n",
      "Y_train shape: (1, 891)\n",
      "X_test shape: (21, 418)\n"
     ]
    }
   ],
   "source": [
    "# Get the output feature and save as its own column\n",
    "\n",
    "Y_train = train_df['Survived']\n",
    "X_train = train_df.drop('Survived', axis=1)\n",
    "\n",
    "# Convert pandas to numpy\n",
    "\n",
    "X_train = X_train.iloc[:] # all rows\n",
    "X_test = test_df.iloc[:]\n",
    "\n",
    "Y_train = Y_train.iloc[:]\n",
    "#Y_test = *** not available in datasets given***\n",
    "\n",
    "# let each column represent one data entry\n",
    "\n",
    "X_train = X_train.values.T\n",
    "X_test = X_test.values.T\n",
    "Y_train = Y_train.values.T\n",
    "Y_train.shape = (1,891)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1])) \n",
    "print (\"number of test examples = \" + str(X_test.shape[1])) \n",
    "print (\"X_train shape: \" + str(X_train.shape)) \n",
    "print (\"Y_train shape: \" + str(Y_train.shape)) \n",
    "print (\"X_test shape: \" + str(X_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions in model\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None])\n",
    "    return X,Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    # input layer      : 21 nodes\n",
    "    # 1st hidden layer : 5 nodes\n",
    "    # 2nd hidden layer : 3 nodes\n",
    "    # output layer     : 1 node\n",
    "    \n",
    "    W1 = tf.get_variable('W1', [5,21], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable('b1', [5,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [3,5], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable('b2', [3,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [1,3], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.get_variable('b3', [1,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    parameters = {'W1': W1,\n",
    "                 'b1': b1,\n",
    "                 'W2': W2,\n",
    "                 'b2': b2,\n",
    "                 'W3': W3,\n",
    "                 'b3': b3}\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y, parameters):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    #L2_regularization_cost = np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))\n",
    "    \n",
    "    beta = 0.01\n",
    "    regularizers = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3)\n",
    "    cost = tf.reduce_mean(cost + beta*regularizers)\n",
    "    \n",
    "    #cost = cost + L2_regularization_cost\n",
    "    return cost\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 20):\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # shuffle X and Y\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    \n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # last batch\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, learning_rate = 0.001,\n",
    "         num_epochs = 1000, minibatch_size = 10, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    (n_x,m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3,Y, parameters)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, minibatch_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print('Epoch %i cost: %f' % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0 and epoch >= 0:\n",
    "                costs.append(epoch_cost)\n",
    "                costs.append(epoch_cost)\n",
    "                costs.append(epoch_cost)\n",
    "                costs.append(epoch_cost)\n",
    "                costs.append(epoch_cost)\n",
    "        \n",
    "        plt.plot(np.squeeze(costs),lw=0.5)\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Learning rate='+str(learning_rate))\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        print('parameters trained')\n",
    "        \n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(tf.sigmoid(Z3)), tf.round(Y))\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        \n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        #print(\"Test Accuracy:\",  accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost: 0.869539\n",
      "Epoch 100 cost: 0.536873\n",
      "Epoch 200 cost: 0.505078\n",
      "Epoch 300 cost: 0.493494\n",
      "Epoch 400 cost: 0.487391\n",
      "Epoch 500 cost: 0.470903\n",
      "Epoch 600 cost: 0.480055\n",
      "Epoch 700 cost: 0.497128\n",
      "Epoch 800 cost: 0.488056\n",
      "Epoch 900 cost: 0.467157\n",
      "Epoch 1000 cost: 0.468242\n",
      "Epoch 1100 cost: 0.473338\n",
      "Epoch 1200 cost: 0.483814\n",
      "Epoch 1300 cost: 0.467320\n",
      "Epoch 1400 cost: 0.464642\n",
      "parameters trained\n",
      "Train Accuracy: 0.817059\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164c8de9f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, learning_rate = 0.0003, num_epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "         0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "         0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "         1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "         1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
       "         0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "         0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "         1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "         0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "         1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "         0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
       "         0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,\n",
       "         0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "         0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "         1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "         0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "         0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "         0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
       "         1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
       "         0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "         0.,  1.]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# use trained parameters to make predictions given X_test from Kaggle\n",
    "\n",
    "def predict(parameters, X_test):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = np.add(np.dot(W1, X_test), b1)\n",
    "    A1 = np.maximum(Z1, 0)\n",
    "    Z2 = np.add(np.dot(W2, A1), b2)\n",
    "    A2 = np.maximum(Z2, 0)\n",
    "    Z3 = np.add(np.dot(W3, A2), b3)\n",
    "    \n",
    "    predict = sigmoid(Z3)\n",
    "    \n",
    "    for i in range(predict.size):\n",
    "        if predict[:,i] < 0.5:\n",
    "            predict[:,i] = 0\n",
    "        else:\n",
    "            predict[:,i] = 1           \n",
    "    return predict\n",
    "    \n",
    "Y_test_predict = predict(parameters, X_test)\n",
    "Y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_test_predict had 77% accuracy when submitted to Kaggle\n",
    "https://www.kaggle.com/c/titanic/leaderboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
